# 📚 Web Scraping & Data Cleaning Portfolio

Python（Requests / BeautifulSoup4 / Pandas）を使用した  
**スクレイピング ＆ データクリーニングのポートフォリオ集**です。

実務でよく使われる「データ取得→整形→CSV出力」までの一連の処理をまとめています。

---

# 🚀 プロジェクト一覧

## ① Books Scraping Tool（スクレイピング）
練習サイト **Books to Scrape** から  
複数ページの本のタイトル・価格・在庫を取得し、CSVに保存するツール。

- スクレイピング（Requests / BeautifulSoup4）
- ページネーション対応
- CSV出力
- エラー時の例外処理付き

📄 **ファイル:** `books_portfolio.py`


---

## ② CSV Company Cleaner（データ整形ツール）
企業リストCSVを読み込み、以下を自動で実施するデータクリーニングツール。

- 全角 → 半角に統一（NFKC正規化）
- 余計な空白削除
- 電話番号の整形（数字＋ハイフンのみに）
- 住所の整形
- 重複企業の削除
- 新しいCSVとして出力

📄 **ファイル:** `csv-company-cleaner.py`

---

# 🛠 使用技術

- Python 3.x
- Pandas
- Requests
- BeautifulSoup4
- 正規化（unicodedata）
- 正規表現（re）

---

# ✨ できること（スキル一覧）
- Webサイトからのデータ取得（スクレイピング）
- APIでのデータ取得準備（requestsベース）
- CSVの整形・クリーニング・標準化
- データの重複除去
- 住所/電話番号データのフォーマット統一
- Pythonスクリプトの作成・運用

---

# 📬 連絡先
副業・単発案件のご相談も歓迎しています。

